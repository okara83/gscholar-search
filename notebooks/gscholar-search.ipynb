{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83752e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "from datetime import datetime\n",
    "import json\n",
    "from serpapi import GoogleSearch, GoogleScholarSearch\n",
    "import os\n",
    "from urllib.parse import urlsplit, parse_qsl\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1803ee38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScholarListener:\n",
    "    def __init__(self,query_list=None,save_to_json=True,save_to_csv=False,return_output_object=False,mauthors=None,affiliations=None,author_id=None,query=None):\n",
    "        self.query_list = query_list\n",
    "        self.return_output_object = return_output_object\n",
    "        self.save_to_json = save_to_json\n",
    "        self.save_to_csv = save_to_csv\n",
    "        self.mauthors = mauthors\n",
    "        self.affiliations=affiliations\n",
    "        self.author_id= author_id\n",
    "        self.query=query\n",
    "\n",
    "    def serpapi_scrape_organic_results(self):\n",
    "        params = {\n",
    "        \"api_key\": \"\",\n",
    "        \"engine\": \"google_scholar\",\n",
    "        \"q\": self.query,\n",
    "        }\n",
    "\n",
    "        search = GoogleScholarSearch(params)\n",
    "        results = search.get_dict()\n",
    "        outward= {}\n",
    "        # It looks a bit akward but the point is that you can grab everything you need in 2-3 lines of code as below.\n",
    "        for result in results['organic_results']:\n",
    "            try:\n",
    "                title= result['title']\n",
    "            except:\n",
    "                continue\n",
    "            try:\n",
    "                publication_info=result['publication_info']['summary']\n",
    "            except:\n",
    "                 publication_info=\"NA\"\n",
    "            try:\n",
    "                snippet=result['snippet']\n",
    "            except:\n",
    "                snippet=\"NA\"\n",
    "            try:\n",
    "                cited_by=result['inline_links']['cited_by']['link']\n",
    "            except:\n",
    "                cited_by=\"NA\"\n",
    "            try:\n",
    "                related_versions=result['inline_links']['related_pages_link']\n",
    "            except:\n",
    "                related_versions=\"NA\"\n",
    "\n",
    "\n",
    "            outward[title]={\n",
    "                  'title': title,\n",
    "                  'publication_info':publication_info,\n",
    "                  'snippet': snippet,\n",
    "                  'cited_by': cited_by,\n",
    "                  'related_versions': related_versions\n",
    "                    }\n",
    "        return outward\n",
    "\n",
    "    def serpapi_scrape_author_result(self):\n",
    "        params = {\n",
    "            \"api_key\": \"\",\n",
    "            \"engine\": \"google_scholar_author\",\n",
    "            \"author_id\": self.author_id,\n",
    "            \"hl\": \"en\",\n",
    "        }\n",
    "\n",
    "        search = GoogleScholarSearch(params)\n",
    "        results = search.get_dict()\n",
    "        print(results)\n",
    "        # Author info\n",
    "        print(results)\n",
    "        name = results['author']['name']\n",
    "        affiliations = results['author']['affiliations']\n",
    "        email = results['author']['email']\n",
    "        interests1 = results['author']['interests'][0]['title']\n",
    "        interests2 = results['author']['interests'][1]['title']\n",
    "\n",
    "        print('Author Info:')\n",
    "        print(f'{name}\\n{affiliations}\\n{email}\\n{interests1}\\n{interests2}\\n')\n",
    "\n",
    "              # Articles Results\n",
    "        for article in results['articles']:\n",
    "            article_title = article['title']\n",
    "            article_link = article['link']\n",
    "            article_authors = article['authors']\n",
    "            article_publication = article['publication']\n",
    "            cited_by = article['cited_by']['value']\n",
    "            cited_by_link = article['cited_by']['link']\n",
    "            article_year = article['year']\n",
    "            print('Articles Info:')\n",
    "            print(f\"Title: {article_title}\\nLink: {article_link}\\nAuthors: {article_authors}\\nPublication: {article_publication}\\nCited by: {cited_by}\\nCited by link: {cited_by_link}\\nPublication year: {article_year}\\n\")\n",
    "\n",
    "        # Cited By and Public Access Results\n",
    "        citations_all = results['cited_by']['table'][0]['citations']['all']\n",
    "        h_inedx_all = results['cited_by']['table'][1]['h_index']['all']\n",
    "        i10_index_all = results['cited_by']['table'][2]['i10_index']['all']\n",
    "\n",
    "        print('Citations Info:')\n",
    "        print(f'{citations_all}\\n{h_inedx_all}\\n{i10_index_all}\\n')\n",
    "        try:\n",
    "            public_access_link = results['public_access']['link']\n",
    "        except:\n",
    "            public_access_link = \"NA\"\n",
    "        try:\n",
    "            public_access_available_articles = results['public_access']['available']\n",
    "        except:\n",
    "            public_access_available_articles = \"NA\"\n",
    "\n",
    "\n",
    "        print('Public Access Info:')\n",
    "        print(f'{public_access_link}\\n{public_access_available_articles}\\n')\n",
    "\n",
    "        # Co-Authors Results\n",
    "        for authors in results['co_authors']:\n",
    "            print(authors)\n",
    "            author_name = authors['name']\n",
    "            try:\n",
    "                author_affiliations = authors['affiliations']\n",
    "            except:\n",
    "                author_affiliations = \"NA\"\n",
    "            try:\n",
    "                author_link = authors['link']\n",
    "            except:\n",
    "                author_link = \"NA\"\n",
    "\n",
    "            print('Co-Authour(s):')\n",
    "            print(f'{author_name}\\n{author_affiliations}\\n{author_link}\\n')\n",
    "        \n",
    "    def serpapi_author_profile(self):\n",
    "        params = {\n",
    "            \"api_key\": \"\",\n",
    "            \"engine\": \"google_scholar_profiles\",\n",
    "            \"hl\": \"en\",\n",
    "            \"mauthors\": self.mauthors,\n",
    "            \"affiliations\":self.affiliations\n",
    "        }\n",
    "\n",
    "        search = GoogleScholarSearch(params)\n",
    "    #     results = search.get_response()\n",
    "        results = search.get_dict()\n",
    "        outputs = {}\n",
    "        author_profiles=results[\"profiles\"]\n",
    "        for result in author_profiles:\n",
    "            try:\n",
    "                self.affiliations.strip()\n",
    "                if result[\"affiliations\"].strip().lower() ==f\"{self.affiliations}\".lower():\n",
    "                    outputs[result[\"name\"]]=result\n",
    "                else:\n",
    "                    continue\n",
    "            except:\n",
    "                outputs[result[\"name\"]]=result   \n",
    "        return outputs\n",
    "    \n",
    "    def scholar_search(self):\n",
    "        '''\n",
    "        query_list = [\"Sehanobish Corzo Kara\", \"Learning potentials of \n",
    "        quantum systems using deep neural networks\", \"2006.13297\" ] \n",
    "        '''\n",
    "        \n",
    "        scraped_time = datetime.now().strftime(\"%h-%d-%Y\")\n",
    "        output = {}\n",
    "        headers = {\"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 12_3_1) AppleWebKit/601.3.9 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36\" ,'referer':'https://www.google.com/'}\n",
    "#         headers = {'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 12_3_1) AppleWebKit/601.3.9 (KHTML, like Gecko) Version/9.0.2 Safari/601.3.9'}\n",
    "        ql = self.query_list\n",
    "        for query in ql:\n",
    "            output_list = []\n",
    "            url_1 = f'https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q={query}&btnG='\n",
    "            url_2 = f'https://scholar.google.com/scholar?start=10&q={query}&hl=en&as_sdt=0,31'\n",
    "            url_3 = f'https://scholar.google.com/scholar?start=20&q={query}&hl=en&as_sdt=0,31'\n",
    "            urls = [url_1,url_2,url_3] # first three search result pages\n",
    "            for url in urls:\n",
    "                response=requests.get(url,headers=headers)\n",
    "                statuscode=response.status_code\n",
    "                if statuscode != 200:\n",
    "                    raise Exception(f\"requests response for url query: {url} returned {statuscode} response -- check google hasn't blocked your IP\")\n",
    "                    return\n",
    "                soup=BeautifulSoup(response.content,'lxml')\n",
    "                links = soup.find_all(\"h3\", class_=\"gs_rt\")\n",
    "                print(links)\n",
    "                for j in links:\n",
    "                    the_url = re.search(\"href=\\\"(.*?)\\\"\\s\",str(j),re.DOTALL)[1]\n",
    "                    output_list.append(the_url)\n",
    "                    prin(the_url)\n",
    "            output[query] = output_list\n",
    "        \n",
    "        #object output and saving results\n",
    "        if self.save_to_json == True:\n",
    "            name_concat_queries = \"_\".join(self.query_list)\n",
    "            with open(f\"{name_concat_queries}--{scraped_time}\",\"w\") as file:\n",
    "                json.dump(output,file)\n",
    "        \n",
    "        if self.save_to_csv == True:\n",
    "            import pandas as pd\n",
    "            for l in output.keys():\n",
    "                df = pd.DataFrame.from_dict(output[l])\n",
    "                df.to_csv(f\"{l}.csv\")\n",
    "                \n",
    "        if self.return_output_object == True:\n",
    "            return output\n",
    "        else:\n",
    "            return            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3598aed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://serpapi.com/search\n",
      "{'error': 'Invalid API key. Your API key should be here: https://serpapi.com/manage-api-key'}\n",
      "{'error': 'Invalid API key. Your API key should be here: https://serpapi.com/manage-api-key'}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'author'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sd/1vc_q83x5rn9jjrd0x47_cc00000gn/T/ipykernel_90671/3852355462.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthor_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"IzsyeRAAAAAJ\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmauthor\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"kara, onur\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserpapi_scrape_author_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/sd/1vc_q83x5rn9jjrd0x47_cc00000gn/T/ipykernel_90671/2296190.py\u001b[0m in \u001b[0;36mserpapi_scrape_author_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m# Author info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'author'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0maffiliations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'author'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'affiliations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0memail\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'author'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'email'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'author'"
     ]
    }
   ],
   "source": [
    "p=ScholarListener()\n",
    "p.author_id=\"IzsyeRAAAAAJ\"\n",
    "p.mauthor= \"kara, onur\"\n",
    "p.serpapi_scrape_author_result()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e3a32d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://serpapi.com/search\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'organic_results'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sd/1vc_q83x5rn9jjrd0x47_cc00000gn/T/ipykernel_90671/1164826190.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Sehanobish Corzo Kara\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserpapi_scrape_organic_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/sd/1vc_q83x5rn9jjrd0x47_cc00000gn/T/ipykernel_90671/2296190.py\u001b[0m in \u001b[0;36mserpapi_scrape_organic_results\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moutward\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# It looks a bit akward but the point is that you can grab everything you need in 2-3 lines of code as below.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'organic_results'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'organic_results'"
     ]
    }
   ],
   "source": [
    "p.query=\"Sehanobish Corzo Kara\"\n",
    "p.serpapi_scrape_organic_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "511c59cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://serpapi.com/search\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Onur Kara': {'name': 'Onur Kara',\n",
       "  'link': 'https://scholar.google.com/citations?hl=en&user=IzsyeRAAAAAJ',\n",
       "  'serpapi_link': 'https://serpapi.com/search.json?author_id=IzsyeRAAAAAJ&engine=google_scholar_author&hl=en',\n",
       "  'author_id': 'IzsyeRAAAAAJ',\n",
       "  'affiliations': 'Hindsight Technology Solutions',\n",
       "  'email': 'Verified email at hindsightsolutions.net',\n",
       "  'cited_by': 8,\n",
       "  'interests': [{'title': 'network science',\n",
       "    'serpapi_link': 'https://serpapi.com/search.json?engine=google_scholar_profiles&hl=en&mauthors=label%3Anetwork_science',\n",
       "    'link': 'https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=label:network_science'},\n",
       "   {'title': 'machine learning',\n",
       "    'serpapi_link': 'https://serpapi.com/search.json?engine=google_scholar_profiles&hl=en&mauthors=label%3Amachine_learning',\n",
       "    'link': 'https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=label:machine_learning'},\n",
       "   {'title': 'statistical physics',\n",
       "    'serpapi_link': 'https://serpapi.com/search.json?engine=google_scholar_profiles&hl=en&mauthors=label%3Astatistical_physics',\n",
       "    'link': 'https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=label:statistical_physics'},\n",
       "   {'title': 'data science',\n",
       "    'serpapi_link': 'https://serpapi.com/search.json?engine=google_scholar_profiles&hl=en&mauthors=label%3Adata_science',\n",
       "    'link': 'https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=label:data_science'},\n",
       "   {'title': 'computational science',\n",
       "    'serpapi_link': 'https://serpapi.com/search.json?engine=google_scholar_profiles&hl=en&mauthors=label%3Acomputational_science',\n",
       "    'link': 'https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=label:computational_science'}],\n",
       "  'thumbnail': 'https://scholar.googleusercontent.com/citations?view_op=small_photo&user=IzsyeRAAAAAJ&citpid=2'}}"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.mauthors=\"kara, onur\"\n",
    "p.affiliations=\"Hindsight Technology Solutions\"\n",
    "p.serpapi_author_profile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "91724552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://serpapi.com/search\n"
     ]
    }
   ],
   "source": [
    "p.query=\"Sehanobish Corzo Kara\"\n",
    "all_info = p.serpapi_scrape_organic_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "05bce9bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Learning potentials of quantum systems using deep neural networks': {'title': 'Learning potentials of quantum systems using deep neural networks',\n",
       "  'publication_info': 'A Sehanobish, HH Corzo, O Kara… - arXiv preprint arXiv …, 2020 - arxiv.org',\n",
       "  'snippet': 'Attempts to apply Neural Networks (NN) to a wide range of research problems have been ubiquitous and plentiful in recent literature. Particularly, the use of deep NNs for understanding …',\n",
       "  'cited_by': 'https://scholar.google.com/scholar?cites=11804469877329258063&as_sdt=5,36&sciodt=0,36&hl=en',\n",
       "  'related_versions': 'https://scholar.google.com/scholar?q=related:T2YCiM_m0aMJ:scholar.google.com/&scioq=Sehanobish+Corzo+Kara&hl=en&as_sdt=0,36'},\n",
       " 'Fine-tuning Vision Transformers for the Prediction of State Variables in Ising Models': {'title': 'Fine-tuning Vision Transformers for the Prediction of State Variables in Ising Models',\n",
       "  'publication_info': 'O Kara, A Sehanobish, HH Corzo - arXiv preprint arXiv:2109.13925, 2021 - arxiv.org',\n",
       "  'snippet': 'Transformers are state-of-the-art deep learning models that are composed of stacked attention and point-wise, fully connected layers designed for handling sequential data. …',\n",
       "  'cited_by': 'https://scholar.google.com/scholar?cites=14144613611479670813&as_sdt=5,36&sciodt=0,36&hl=en',\n",
       "  'related_versions': 'https://scholar.google.com/scholar?q=related:HaBmZSPDS8QJ:scholar.google.com/&scioq=Sehanobish+Corzo+Kara&hl=en&as_sdt=0,36'},\n",
       " 'Application of the Quantum Potential Neural Network to multi-electronic atoms': {'title': 'Application of the Quantum Potential Neural Network to multi-electronic atoms',\n",
       "  'publication_info': 'HH Corzo, A Sehanobish, O Kara - arXiv preprint arXiv:2106.08138, 2021 - arxiv.org',\n",
       "  'snippet': 'In this report, the application of the Quantum Potential Neural Network (QPNN) framework to many electron atomic systems is presented. For this study, full configuration interaction (FCI) …',\n",
       "  'cited_by': 'NA',\n",
       "  'related_versions': 'https://scholar.google.com/scholar?q=related:BbCbqVJC0rQJ:scholar.google.com/&scioq=Sehanobish+Corzo+Kara&hl=en&as_sdt=0,36'},\n",
       " 'Learning Full Configuration Interaction Electron Correlations with Deep Learning': {'title': 'Learning Full Configuration Interaction Electron Correlations with Deep Learning',\n",
       "  'publication_info': 'HH Corzo, A Sehanobish, O Kara - ml4physicalsciences.github.io',\n",
       "  'snippet': 'In this report, we present a deep learning framework termed the Electron Correlation Potential Neural Network (eCPNN) that can learn succinct and compact potential functions. These …',\n",
       "  'cited_by': 'NA',\n",
       "  'related_versions': 'https://scholar.google.com/scholar?q=related:mh2XCm7p1YYJ:scholar.google.com/&scioq=Sehanobish+Corzo+Kara&hl=en&as_sdt=0,36'},\n",
       " 'Deep Learning Quantum States for Hamiltonian Estimation': {'title': 'Deep Learning Quantum States for Hamiltonian Estimation',\n",
       "  'publication_info': 'X Ma, ZC Tu, SJ Ran - Chinese Physics Letters, 2021 - iopscience.iop.org',\n",
       "  'snippet': 'Human experts cannot efficiently access physical information of a quantum many-body states by simply\" reading\" its coefficients, but have to reply on the previous knowledge such as …',\n",
       "  'cited_by': 'https://scholar.google.com/scholar?cites=13935163193403524492&as_sdt=5,36&sciodt=0,36&hl=en',\n",
       "  'related_versions': 'https://scholar.google.com/scholar?q=related:jEXqvRelY8EJ:scholar.google.com/&scioq=Sehanobish+Corzo+Kara&hl=en&as_sdt=0,36'},\n",
       " 'Predicting quantum potentials by deep neural network and metropolis sampling': {'title': 'Predicting quantum potentials by deep neural network and metropolis sampling',\n",
       "  'publication_info': 'R Hong, PF Zhou, B Xi, J Hu, AC Ji, SJ Ran - SciPost Physics Core, 2021 - scipost.org',\n",
       "  'snippet': 'The hybridizations of machine learning and quantum physics have caused essential impacts to the methodology in both fields. Inspired by quantum potential neural network, we here …',\n",
       "  'cited_by': 'https://scholar.google.com/scholar?cites=267322141856673560&as_sdt=5,36&sciodt=0,36&hl=en',\n",
       "  'related_versions': 'https://scholar.google.com/scholar?q=related:GK_2WRK4tQMJ:scholar.google.com/&scioq=Sehanobish+Corzo+Kara&hl=en&as_sdt=0,36'},\n",
       " 'Emojich--zero-shot emoji generation using Russian language: a technical report': {'title': 'Emojich--zero-shot emoji generation using Russian language: a technical report',\n",
       "  'publication_info': 'A Shonenkov, D Bakshandaeva, D Dimitrov… - arXiv preprint arXiv …, 2021 - arxiv.org',\n",
       "  'snippet': 'This technical report presents a text-to-image neural network \"Emojich\" that generates emojis using captions in Russian language as a condition. We aim to keep the generalization …',\n",
       "  'cited_by': 'NA',\n",
       "  'related_versions': 'https://scholar.google.com/scholar?q=related:2l6atLb7x-oJ:scholar.google.com/&scioq=Sehanobish+Corzo+Kara&hl=en&as_sdt=0,36'},\n",
       " 'Deep learning Local Reduced Density Matrices for Many-body Hamiltonian Estimation': {'title': 'Deep learning Local Reduced Density Matrices for Many-body Hamiltonian Estimation',\n",
       "  'publication_info': 'X Ma, ZC Tu, SJ Ran - arXiv preprint arXiv:2012.03019, 2020 - arxiv.org',\n",
       "  'snippet': '… Sehanobish et al proposed the quantum potential neural networks to reconstruct the … Kara, and D. van Dijk, Learning potentials of quantum systems using deep neural networks, arXiv …',\n",
       "  'cited_by': 'NA',\n",
       "  'related_versions': 'https://scholar.google.com/scholar?q=related:LpzVvKoMAf8J:scholar.google.com/&scioq=Sehanobish+Corzo+Kara&hl=en&as_sdt=0,36'},\n",
       " 'Neural Network Approach to Construction of Classical Integrable Systems': {'title': 'Neural Network Approach to Construction of Classical Integrable Systems',\n",
       "  'publication_info': 'F Ishikawa, H Suwa, S Todo - Journal of the Physical Society of …, 2021 - journals.jps.jp',\n",
       "  'snippet': 'Integrable systems have provided various insights into physical phenomena and mathematics. The way of constructing many-body integrable systems is limited to few ansatzes for the …',\n",
       "  'cited_by': 'NA',\n",
       "  'related_versions': 'https://scholar.google.com/scholar?q=related:1dYi3dooLkwJ:scholar.google.com/&scioq=Sehanobish+Corzo+Kara&hl=en&as_sdt=0,36'},\n",
       " 'Functional tensor network solving many-body Schrödinger equation': {'title': 'Functional tensor network solving many-body Schrödinger equation',\n",
       "  'publication_info': 'R Hong, YX Xiao, J Hu, AC Ji, SJ Ran - Physical Review B, 2022 - APS',\n",
       "  'snippet': 'Solving the many-body Schrödinger equation in continuous spaces with the presence of strong correlations is an extremely important and challenging issue in quantum physics. In this …',\n",
       "  'cited_by': 'NA',\n",
       "  'related_versions': 'NA'}}"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "056f7632",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.query_list = [\"Sehanobish Corzo Kara\", \"Learning potentials of quantum systems using deep neural networks\", \"2006.13297\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "9bd2a177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sehanobish Corzo Kara',\n",
       " 'Learning potentials of quantum systems using deep neural networks',\n",
       " '2006.13297']"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.query_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "f675df9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.save_to_csv = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "5af9d924",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "requests response for url query: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=Sehanobish Corzo Kara&btnG= returned 429 response -- check google hasn't blocked your IP",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sd/1vc_q83x5rn9jjrd0x47_cc00000gn/T/ipykernel_63375/1250562138.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscholar_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/sd/1vc_q83x5rn9jjrd0x47_cc00000gn/T/ipykernel_63375/239751259.py\u001b[0m in \u001b[0;36mscholar_search\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0mstatuscode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstatuscode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"requests response for url query: {url} returned {statuscode} response -- check google hasn't blocked your IP\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m                     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0msoup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lxml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: requests response for url query: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=Sehanobish Corzo Kara&btnG= returned 429 response -- check google hasn't blocked your IP"
     ]
    }
   ],
   "source": [
    "p.scholar_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "4fff92af",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.return_output_object= True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "d23ed32e",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "requests response for url query: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=Sehanobish Corzo Kara&btnG= returned 429 response -- check google hasn't blocked your IP",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sd/1vc_q83x5rn9jjrd0x47_cc00000gn/T/ipykernel_63375/916437473.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscholar_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/sd/1vc_q83x5rn9jjrd0x47_cc00000gn/T/ipykernel_63375/239751259.py\u001b[0m in \u001b[0;36mscholar_search\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0mstatuscode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstatuscode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"requests response for url query: {url} returned {statuscode} response -- check google hasn't blocked your IP\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m                     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0msoup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lxml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: requests response for url query: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=Sehanobish Corzo Kara&btnG= returned 429 response -- check google hasn't blocked your IP"
     ]
    }
   ],
   "source": [
    "results = p.scholar_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c205ff58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0be0658",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "6b05d245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "9df1a06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://serpapi.com/search\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "82bddc6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff317d78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adbe96b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
